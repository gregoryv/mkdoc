package main

import (
	"bytes"
	"fmt"
	"io"
)

func run(stderr, stdout io.Writer, stdin io.Reader) {
	w := &bytes.Buffer{}
	r := &bytes.Buffer{}
	io.Copy(r, stdin)
	next := func(step func()) {
		step()
		r, w = w, r
	}

	// first pass; include files
	next(func() { cat(stderr, w, r, "<>") })

	// parse links early
	var links map[string]string
	next(func() { links = parselinks(w, r) })

	var requirements []string
	next(func() { requirements = parsereq(w, r) })

	// requirements must be indexed (#R...)
	next(func() { checkreq(stderr, w, r) }) // #R8
	next(func() { sentenceSpace(stderr, w, r) })
	next(func() { emptyLines(stderr, w, r) })
	next(func() { includeReq(w, r, requirements) })

	// lines starting with `[\d+] ...`
	next(func() { replacerefs(w, r) })

	next(func() { dropcomments(w, r) })

	next(func() { rfcindent(w, r) })

	// second pass; parse toc and index sections
	var toc bytes.Buffer
	cols := 69
	next(func() { parsetoc(stderr, w, &toc, r, cols) })
	next(func() { linksections(stderr, w, r) })

	// insert toc
	next(func() { inserttoc(w, r, &toc) })

	// before replacing ordinary links
	next(func() { replaceRequirements(stderr, w, r) })

	// replace links, also includes reference links
	next(func() { replacelinks(stderr, w, r, links) })

	next(func() { replaceSections(stderr, w, r) })

	fmt.Fprintln(stdout, htmlHeader)
	io.Copy(stdout, r)
	fmt.Fprintln(stdout, htmlFooter)
}

const htmlHeader = `<!DOCTYPE html>

<meta charset="utf-8">
<pre>`

const htmlFooter = `</pre>
<!-- GENERATED by github.com/gregoryv/stp. DO NOT EDIT! -->`
