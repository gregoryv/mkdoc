package main

import (
	"bytes"
	"fmt"
	"io"
	"log"
)

func run(err, out io.Writer, in io.Reader) {
	log.SetOutput(err)
	w := &bytes.Buffer{}
	r := &bytes.Buffer{}
	io.Copy(r, in)
	next := func(step func()) {
		step()
		r, w = w, r
	}

	// first pass; include files
	next(func() { cat(w, r, "<>") })

	// parse links early
	var links map[string]string
	next(func() { links = parselinks(w, r) })

	var requirements []string
	next(func() { requirements = parsereq(w, r) })

	// requirements must be indexed (#R...)
	next(func() { checkreq(err, w, r) }) // #R8
	next(func() { sentenceSpace(w, r) })
	next(func() { emptyLines(w, r) })
	next(func() { includeReq(w, r, requirements) })

	// lines starting with `[\d+] ...`
	next(func() { replacerefs(w, r) })

	next(func() { dropcomments(w, r) })

	next(func() { rfcindent(w, r) })

	// second pass; parse toc and index sections
	var toc bytes.Buffer
	cols := 69
	next(func() { parsetoc(w, &toc, r, cols) })
	next(func() { linksections(w, r) })

	// insert toc
	next(func() { inserttoc(w, r, &toc) })

	// before replacing ordinary links
	next(func() { replaceRequirements(w, r) })

	// replace links, also includes reference links
	next(func() { replacelinks(w, r, links) })

	next(func() { replaceSections(w, r) })

	fmt.Fprintln(out, htmlHeader)
	io.Copy(out, r)
	fmt.Fprintln(out, htmlFooter)
}

const htmlHeader = `<!DOCTYPE html>

<meta charset="utf-8">
<pre>`

const htmlFooter = `</pre>
<!-- GENERATED by github.com/gregoryv/stp. DO NOT EDIT! -->`
